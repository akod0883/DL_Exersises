{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport json\nimport csv\nimport random\nimport pickle\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport matplotlib.pyplot as plt\nfrom scipy.stats import linregress\nimport random\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-29T22:42:10.593744Z","iopub.execute_input":"2023-03-29T22:42:10.594929Z","iopub.status.idle":"2023-03-29T22:42:10.605253Z","shell.execute_reply.started":"2023-03-29T22:42:10.594884Z","shell.execute_reply":"2023-03-29T22:42:10.602937Z"},"trusted":true},"execution_count":117,"outputs":[]},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:10.636245Z","iopub.execute_input":"2023-03-29T22:42:10.636685Z","iopub.status.idle":"2023-03-29T22:42:10.647541Z","shell.execute_reply.started":"2023-03-29T22:42:10.636640Z","shell.execute_reply":"2023-03-29T22:42:10.645846Z"},"trusted":true},"execution_count":118,"outputs":[{"name":"stdout","text":"/kaggle/input/whats-cooking-kernels-only/sample_submission.csv.zip\n/kaggle/input/whats-cooking-kernels-only/train.json\n/kaggle/input/whats-cooking-kernels-only/test.json\n","output_type":"stream"}]},{"cell_type":"code","source":"# Open the JSON file\nwith open('/kaggle/input/whats-cooking-kernels-only/train.json', 'r') as f:\n    # Load the JSON data into a Python dictionary\n    train_data = json.load(f)\n\nwith open('/kaggle/input/whats-cooking-kernels-only/test.json', 'r') as f:\n    # Load the JSON data into a Python dictionary\n    test_data = json.load(f)    \n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:10.651145Z","iopub.execute_input":"2023-03-29T22:42:10.651698Z","iopub.status.idle":"2023-03-29T22:42:10.908589Z","shell.execute_reply.started":"2023-03-29T22:42:10.651645Z","shell.execute_reply":"2023-03-29T22:42:10.907620Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"def check_null(data):\n    # Check if any field contains a null value\n    contains_null = False\n    for j in data:\n        data = j\n        for key, value in data.items():\n            if value is None:\n                contains_null = True\n                break\n\n    # Print the result\n    if contains_null:\n        print(\"The JSON object contains a null value\")\n    else:\n        print(\"The JSON object does not contain a null value\")        \n\ncheck_null(train_data)\ncheck_null(test_data)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:10.910257Z","iopub.execute_input":"2023-03-29T22:42:10.911411Z","iopub.status.idle":"2023-03-29T22:42:10.959181Z","shell.execute_reply.started":"2023-03-29T22:42:10.911351Z","shell.execute_reply":"2023-03-29T22:42:10.957985Z"},"trusted":true},"execution_count":120,"outputs":[{"name":"stdout","text":"The JSON object does not contain a null value\nThe JSON object does not contain a null value\n","output_type":"stream"}]},{"cell_type":"code","source":"# constants\nEMBEDDING_DIM = 100\nMAXLEN = 65\nTRUNCATING = 'post'\nPADDING = 'post'\nOOV_TOKEN = \"<OOV>\"\nMAX_EXAMPLES = 160000\nTRAINING_SPLIT = 0.9","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:10.960343Z","iopub.execute_input":"2023-03-29T22:42:10.961396Z","iopub.status.idle":"2023-03-29T22:42:10.966666Z","shell.execute_reply.started":"2023-03-29T22:42:10.961355Z","shell.execute_reply":"2023-03-29T22:42:10.965627Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"train_labels = []\ntrain_ingredients = []\n\ntest_ingredients = []\ntest_ids = []\n\ntrain_data = random.sample(train_data, len(train_data))\n\nfor j in train_data:\n    train_labels.append(j['cuisine'])\n    train_ingredients.append(j['ingredients'])    \n    \nfor j in test_data:\n    test_ingredients.append(j['ingredients'])\n    test_ids.append(j['id'])\n    \nall_labels = train_labels.copy()","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:10.969131Z","iopub.execute_input":"2023-03-29T22:42:10.970319Z","iopub.status.idle":"2023-03-29T22:42:11.108503Z","shell.execute_reply.started":"2023-03-29T22:42:10.970270Z","shell.execute_reply":"2023-03-29T22:42:11.107069Z"},"trusted":true},"execution_count":122,"outputs":[]},{"cell_type":"code","source":"print(len(test_ids))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:11.109966Z","iopub.execute_input":"2023-03-29T22:42:11.110325Z","iopub.status.idle":"2023-03-29T22:42:11.116546Z","shell.execute_reply.started":"2023-03-29T22:42:11.110290Z","shell.execute_reply":"2023-03-29T22:42:11.115601Z"},"trusted":true},"execution_count":123,"outputs":[{"name":"stdout","text":"9944\n","output_type":"stream"}]},{"cell_type":"code","source":"# Find the length of the biggest ingrediants list\nmax_len = max([len(lst) for lst in train_ingredients])\n\n# Print the result\nprint(\"The length of the biggest list is:\", max_len)\nMAXLEN = 65","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:11.118000Z","iopub.execute_input":"2023-03-29T22:42:11.118624Z","iopub.status.idle":"2023-03-29T22:42:11.144389Z","shell.execute_reply.started":"2023-03-29T22:42:11.118566Z","shell.execute_reply":"2023-03-29T22:42:11.142657Z"},"trusted":true},"execution_count":124,"outputs":[{"name":"stdout","text":"The length of the biggest list is: 65\n","output_type":"stream"}]},{"cell_type":"code","source":"def split_data(input_data, split_ratio):\n    input_data_split_size = int(len(input_data) * split_ratio)\n    train_data = input_data[0:input_data_split_size]\n    val_data = input_data[input_data_split_size:]\n    \n    return train_data, val_data\n\ntrain_ingredients, val_ingredients = split_data(train_ingredients, TRAINING_SPLIT)\ntrain_labels, val_labels = split_data(train_labels, TRAINING_SPLIT)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:11.145833Z","iopub.execute_input":"2023-03-29T22:42:11.146223Z","iopub.status.idle":"2023-03-29T22:42:11.162272Z","shell.execute_reply.started":"2023-03-29T22:42:11.146173Z","shell.execute_reply":"2023-03-29T22:42:11.160844Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"def fit_tokenizer(train_sentences, oov_token):\n    \n    ### START CODE HERE\n    \n    # Instantiate the Tokenizer class, passing in the correct values for num_words and oov_token\n    tokenizer = Tokenizer(oov_token=oov_token)\n    \n    # Fit the tokenizer to the training sentences\n    tokenizer.fit_on_texts(train_sentences)\n    \n    ### END CODE HERE\n    \n    return tokenizer\n\ntokenizer_ingredients = fit_tokenizer(train_ingredients, OOV_TOKEN)\nword_index_ingredients = tokenizer_ingredients.word_index\nVOCAB_SIZE = len(word_index_ingredients)\n\nprint(f\"Vocabulary contains {VOCAB_SIZE} words\\n\")\nprint(\"<OOV> token included in vocabulary\" if \"<OOV>\" in word_index_ingredients else \"<OOV> token NOT included in vocabulary\")","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:11.164211Z","iopub.execute_input":"2023-03-29T22:42:11.164619Z","iopub.status.idle":"2023-03-29T22:42:11.601218Z","shell.execute_reply.started":"2023-03-29T22:42:11.164575Z","shell.execute_reply":"2023-03-29T22:42:11.599717Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"Vocabulary contains 6517 words\n\n<OOV> token included in vocabulary\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_labels(all_labels, split_labels):\n    \n    ### START CODE HERE\n    \n    # Instantiate the Tokenizer (no additional arguments needed)\n    label_tokenizer = Tokenizer(filters=\" \")\n    \n    # Fit the tokenizer on all the labels\n    label_tokenizer.fit_on_texts(all_labels)\n    \n    # Convert labels to sequences\n    label_seq = label_tokenizer.texts_to_sequences(split_labels)\n    print(label_tokenizer.word_index)\n    # Convert sequences to a numpy array. Don't forget to substact 1 from every entry in the array!\n    label_seq_np = np.array(label_seq) - 1\n    \n    ### END CODE HERE\n    \n    return label_seq_np, label_tokenizer\n\ntrain_label_seq, train_label_tokenizer = tokenize_labels(all_labels, train_labels)\nval_label_seq, val_label_tokenizer = tokenize_labels(all_labels, val_labels)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:11.603103Z","iopub.execute_input":"2023-03-29T22:42:11.603608Z","iopub.status.idle":"2023-03-29T22:42:12.075732Z","shell.execute_reply.started":"2023-03-29T22:42:11.603531Z","shell.execute_reply":"2023-03-29T22:42:12.074742Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"{'italian': 1, 'mexican': 2, 'southern_us': 3, 'indian': 4, 'chinese': 5, 'french': 6, 'cajun_creole': 7, 'thai': 8, 'japanese': 9, 'greek': 10, 'spanish': 11, 'korean': 12, 'vietnamese': 13, 'moroccan': 14, 'british': 15, 'filipino': 16, 'irish': 17, 'jamaican': 18, 'russian': 19, 'brazilian': 20}\n{'italian': 1, 'mexican': 2, 'southern_us': 3, 'indian': 4, 'chinese': 5, 'french': 6, 'cajun_creole': 7, 'thai': 8, 'japanese': 9, 'greek': 10, 'spanish': 11, 'korean': 12, 'vietnamese': 13, 'moroccan': 14, 'british': 15, 'filipino': 16, 'irish': 17, 'jamaican': 18, 'russian': 19, 'brazilian': 20}\n","output_type":"stream"}]},{"cell_type":"code","source":"def seq_pad_and_trunc(sentences, tokenizer, padding, truncating, maxlen):\n    \n    ### START CODE HERE\n       \n    # Convert sentences to sequences\n    sequences = tokenizer.texts_to_sequences(sentences)\n    \n    # Pad the sequences using the correct padding, truncating and maxlen\n#     pad_trunc_sequences = pad_sequences(sequences, maxlen=maxlen, padding=padding, truncating=truncating)\n    pad_trunc_sequences = pad_sequences(sequences, padding=padding, truncating=truncating)\n    \n    ### END CODE HERE\n    \n    return pad_trunc_sequences\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:12.077406Z","iopub.execute_input":"2023-03-29T22:42:12.077913Z","iopub.status.idle":"2023-03-29T22:42:12.085646Z","shell.execute_reply.started":"2023-03-29T22:42:12.077868Z","shell.execute_reply":"2023-03-29T22:42:12.083935Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# Test your function\ntrain_pad_trunc_seq = seq_pad_and_trunc(train_ingredients, tokenizer_ingredients, PADDING, TRUNCATING, MAXLEN)\nval_pad_trunc_seq = seq_pad_and_trunc(val_ingredients, tokenizer_ingredients, PADDING, TRUNCATING, MAXLEN)\n\ntest_pad_trunc_seq = seq_pad_and_trunc(test_ingredients, tokenizer_ingredients, PADDING, TRUNCATING, MAXLEN)\n\nprint(f\"Padded and truncated training sequences have shape: {train_pad_trunc_seq.shape}\\n\")\nprint(f\"Padded and truncated validation sequences have shape: {val_pad_trunc_seq.shape}\")\nprint(f\"Padded and truncated test sequences have shape: {test_pad_trunc_seq.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:12.086960Z","iopub.execute_input":"2023-03-29T22:42:12.087318Z","iopub.status.idle":"2023-03-29T22:42:13.027224Z","shell.execute_reply.started":"2023-03-29T22:42:12.087284Z","shell.execute_reply":"2023-03-29T22:42:13.025787Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"Padded and truncated training sequences have shape: (35796, 65)\n\nPadded and truncated validation sequences have shape: (3978, 36)\nPadded and truncated test sequences have shape: (9944, 50)\n","output_type":"stream"}]},{"cell_type":"code","source":"# GRADED FUNCTION: create_model\ndef create_model(num_words, embedding_dim, maxlen):\n    \n    tf.random.set_seed(123)\n    \n    ### START CODE HERE\n    \n    model = tf.keras.Sequential([ \n#         tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen),\n        tf.keras.layers.Embedding(num_words, embedding_dim),    \n        tf.keras.layers.GlobalAveragePooling1D(),\n        tf.keras.layers.Dense(24, activation='relu'),\n        tf.keras.layers.Dense(24, activation='relu'),        \n        tf.keras.layers.Dropout(0.2),\n        tf.keras.layers.Dense(20, activation='softmax')\n    ])\n    \n    model.compile(loss='sparse_categorical_crossentropy',\n                  optimizer='adam',\n                  metrics=['accuracy']) \n\n    ### END CODE HERE\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:13.029488Z","iopub.execute_input":"2023-03-29T22:42:13.029864Z","iopub.status.idle":"2023-03-29T22:42:13.038373Z","shell.execute_reply.started":"2023-03-29T22:42:13.029829Z","shell.execute_reply":"2023-03-29T22:42:13.036671Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"# train_label_seq = train_label_seq.reshape(35796,)\n# val_label_seq = val_label_seq.reshape(3978,)\ntrain_label_seq = train_label_seq.reshape(-1,)\nval_label_seq = val_label_seq.reshape(-1,)\nprint(train_pad_trunc_seq.shape)\nprint(train_label_seq.shape)\nprint(val_pad_trunc_seq.shape)\nprint(val_label_seq.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:13.043145Z","iopub.execute_input":"2023-03-29T22:42:13.043683Z","iopub.status.idle":"2023-03-29T22:42:13.053352Z","shell.execute_reply.started":"2023-03-29T22:42:13.043644Z","shell.execute_reply":"2023-03-29T22:42:13.051850Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"(35796, 65)\n(35796,)\n(3978, 36)\n(3978,)\n","output_type":"stream"}]},{"cell_type":"code","source":"model = create_model(6544, EMBEDDING_DIM, MAXLEN)\n\nhistory = model.fit(train_pad_trunc_seq, train_label_seq, epochs=30, validation_data=(val_pad_trunc_seq, val_label_seq))","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:42:13.054747Z","iopub.execute_input":"2023-03-29T22:42:13.055090Z","iopub.status.idle":"2023-03-29T22:46:42.613104Z","shell.execute_reply.started":"2023-03-29T22:42:13.055056Z","shell.execute_reply":"2023-03-29T22:46:42.611478Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"Epoch 1/30\n1119/1119 [==============================] - 10s 8ms/step - loss: 2.0912 - accuracy: 0.3657 - val_loss: 1.4272 - val_accuracy: 0.5601\nEpoch 2/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 1.3346 - accuracy: 0.6061 - val_loss: 1.2188 - val_accuracy: 0.6433\nEpoch 3/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 1.1430 - accuracy: 0.6606 - val_loss: 1.1561 - val_accuracy: 0.6657\nEpoch 4/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 1.0436 - accuracy: 0.6869 - val_loss: 1.1237 - val_accuracy: 0.6795\nEpoch 5/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.9729 - accuracy: 0.7059 - val_loss: 1.1015 - val_accuracy: 0.6938\nEpoch 6/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.9191 - accuracy: 0.7239 - val_loss: 1.1233 - val_accuracy: 0.6971\nEpoch 7/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.8789 - accuracy: 0.7379 - val_loss: 1.1412 - val_accuracy: 0.6996\nEpoch 8/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.8439 - accuracy: 0.7481 - val_loss: 1.1298 - val_accuracy: 0.7069\nEpoch 9/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.8134 - accuracy: 0.7602 - val_loss: 1.1522 - val_accuracy: 0.6998\nEpoch 10/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.7913 - accuracy: 0.7651 - val_loss: 1.1526 - val_accuracy: 0.7124\nEpoch 11/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.7687 - accuracy: 0.7698 - val_loss: 1.1713 - val_accuracy: 0.7069\nEpoch 12/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.7518 - accuracy: 0.7746 - val_loss: 1.2106 - val_accuracy: 0.7092\nEpoch 13/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.7383 - accuracy: 0.7805 - val_loss: 1.1912 - val_accuracy: 0.7069\nEpoch 14/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.7206 - accuracy: 0.7849 - val_loss: 1.2024 - val_accuracy: 0.7069\nEpoch 15/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.7111 - accuracy: 0.7865 - val_loss: 1.2487 - val_accuracy: 0.7079\nEpoch 16/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6885 - accuracy: 0.7948 - val_loss: 1.2278 - val_accuracy: 0.7061\nEpoch 17/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6804 - accuracy: 0.7986 - val_loss: 1.2221 - val_accuracy: 0.7182\nEpoch 18/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6597 - accuracy: 0.8037 - val_loss: 1.2072 - val_accuracy: 0.7192\nEpoch 19/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6435 - accuracy: 0.8093 - val_loss: 1.2165 - val_accuracy: 0.7190\nEpoch 20/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6272 - accuracy: 0.8142 - val_loss: 1.2383 - val_accuracy: 0.7174\nEpoch 21/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6120 - accuracy: 0.8181 - val_loss: 1.2740 - val_accuracy: 0.7212\nEpoch 22/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.6001 - accuracy: 0.8206 - val_loss: 1.2975 - val_accuracy: 0.7232\nEpoch 23/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5868 - accuracy: 0.8221 - val_loss: 1.3041 - val_accuracy: 0.7207\nEpoch 24/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5761 - accuracy: 0.8280 - val_loss: 1.3340 - val_accuracy: 0.7305\nEpoch 25/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5693 - accuracy: 0.8298 - val_loss: 1.3676 - val_accuracy: 0.7222\nEpoch 26/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5574 - accuracy: 0.8325 - val_loss: 1.3824 - val_accuracy: 0.7230\nEpoch 27/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5498 - accuracy: 0.8345 - val_loss: 1.3831 - val_accuracy: 0.7265\nEpoch 28/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5395 - accuracy: 0.8378 - val_loss: 1.3985 - val_accuracy: 0.7210\nEpoch 29/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5284 - accuracy: 0.8403 - val_loss: 1.4269 - val_accuracy: 0.7323\nEpoch 30/30\n1119/1119 [==============================] - 9s 8ms/step - loss: 0.5164 - accuracy: 0.8429 - val_loss: 1.4504 - val_accuracy: 0.7235\n","output_type":"stream"}]},{"cell_type":"code","source":"softmax_outputs = model.predict(test_pad_trunc_seq)\nprint(softmax_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:46:42.616255Z","iopub.execute_input":"2023-03-29T22:46:42.616986Z","iopub.status.idle":"2023-03-29T22:46:43.583115Z","shell.execute_reply.started":"2023-03-29T22:46:42.616924Z","shell.execute_reply":"2023-03-29T22:46:43.581756Z"},"trusted":true},"execution_count":133,"outputs":[{"name":"stdout","text":"311/311 [==============================] - 1s 2ms/step\n[[8.6246962e-03 2.3304052e-03 1.2796967e-01 ... 1.3136910e-02\n  9.8664045e-02 1.7717783e-03]\n [8.1992644e-09 7.4570835e-07 9.9993449e-01 ... 2.2835459e-06\n  5.0929287e-07 2.9816121e-07]\n [7.4887878e-01 6.9818072e-02 4.2321739e-05 ... 1.0488388e-09\n  1.1921193e-05 1.1842345e-04]\n ...\n [5.5893809e-01 2.7153874e-04 2.2434574e-01 ... 1.3001803e-05\n  1.9612356e-05 3.2609933e-07]\n [1.2909155e-07 2.1343961e-04 9.9974382e-01 ... 3.4674192e-09\n  2.2969827e-10 1.7950633e-08]\n [8.3842791e-14 9.9999994e-01 5.9348793e-09 ... 2.2616626e-24\n  1.8999456e-25 1.6891812e-08]]\n","output_type":"stream"}]},{"cell_type":"code","source":"softmax_indices = np.argmax(softmax_outputs, axis=1)\nlen(softmax_indices)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:46:43.584486Z","iopub.execute_input":"2023-03-29T22:46:43.585011Z","iopub.status.idle":"2023-03-29T22:46:43.593147Z","shell.execute_reply.started":"2023-03-29T22:46:43.584961Z","shell.execute_reply":"2023-03-29T22:46:43.591761Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"9944"},"metadata":{}}]},{"cell_type":"code","source":"train_label_tokenizer.index_word","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:46:43.594847Z","iopub.execute_input":"2023-03-29T22:46:43.596035Z","iopub.status.idle":"2023-03-29T22:46:43.609031Z","shell.execute_reply.started":"2023-03-29T22:46:43.595991Z","shell.execute_reply":"2023-03-29T22:46:43.607759Z"},"trusted":true},"execution_count":135,"outputs":[{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"{1: 'italian',\n 2: 'mexican',\n 3: 'southern_us',\n 4: 'indian',\n 5: 'chinese',\n 6: 'french',\n 7: 'cajun_creole',\n 8: 'thai',\n 9: 'japanese',\n 10: 'greek',\n 11: 'spanish',\n 12: 'korean',\n 13: 'vietnamese',\n 14: 'moroccan',\n 15: 'british',\n 16: 'filipino',\n 17: 'irish',\n 18: 'jamaican',\n 19: 'russian',\n 20: 'brazilian'}"},"metadata":{}}]},{"cell_type":"code","source":"print(len(test_ids))\npredictions = []\nfor idx in softmax_indices:\n    predictions.append(train_label_tokenizer.index_word[idx+1])\n\npredictions_dict = {\n    'id' : test_ids,\n    'cuisine' : predictions\n}\npredictions_df = pd.DataFrame(predictions_dict)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:46:43.611366Z","iopub.execute_input":"2023-03-29T22:46:43.611970Z","iopub.status.idle":"2023-03-29T22:46:43.638901Z","shell.execute_reply.started":"2023-03-29T22:46:43.611920Z","shell.execute_reply":"2023-03-29T22:46:43.637892Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stdout","text":"9944\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-03-29T22:46:43.640774Z","iopub.execute_input":"2023-03-29T22:46:43.641522Z","iopub.status.idle":"2023-03-29T22:46:43.660829Z","shell.execute_reply.started":"2023-03-29T22:46:43.641481Z","shell.execute_reply":"2023-03-29T22:46:43.659544Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}